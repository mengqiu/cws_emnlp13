\begin{abstract}
There are two dominant approaches to the Chinese word segmentation problem: word-based and character-based models, each with respective strengths and weaknesses. Prior work has shown that gains in segmentation performance can be achieved from combining these two types of models; however, past efforts involve either training many instances of segmenters and polling their results, or designing complex latent-variable methods that incur heavy computational costs. In this paper, we propose an effective and consistent joint decoding method using dual decomposition, which does not require any additional training. Our method is simple and easy to implement, and achieves the best reported results to date on 6 out of 7 standard SIGHAN evaluation datasets.
\end{abstract}

%%
%Word-based approaches are better at capturing longer context dependencies, and achieve higher segmentation consistency, whereas character-based approaches model the internal structures of words and can capture more out-of-vocabulary words. It is an intuitive idea to find methods to combine these approaches. 